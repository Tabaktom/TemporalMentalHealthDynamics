{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jiuc5WKv0Z8r"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ag5aDzsif-X"
   },
   "source": [
    "Import libraries and functions, mount google drive and read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "jmTpKt_uefe5",
    "outputId": "32a0e49a-22fc-417b-e268-b0fd1d3e5250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
      "Name: tensorflow\n",
      "Version: 2.3.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.6/dist-packages\n",
      "Requires: wheel, h5py, numpy, tensorboard, absl-py, tensorflow-estimator, opt-einsum, keras-preprocessing, termcolor, wrapt, grpcio, gast, protobuf, astunparse, six, scipy, google-pasta\n",
      "Required-by: fancyimpute\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "{0: 1.0871637139632675, 1: 12.47266396222421}\n",
      "{0: 1.0871637139632675, 1: 12.47266396222421}\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install tweet-preprocessor\n",
    "!pip3 show tensorflow\n",
    "#!pip install tensorflow-gpu==1.15.2\n",
    "import preprocessor as p\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook, tqdm\n",
    "import requests\n",
    "from io import StringIO\n",
    "from google.colab import drive\n",
    "import string\n",
    "\n",
    "from nltk import ngrams\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "test_path = '/content/drive/My Drive/UK/development/UK_bal_test_indiv.csv'\n",
    "#exp_path ='/content/drive/My Drive/Germany/experiment/indiv_exp.csv'\n",
    "train = pd.read_csv('/content/drive/My Drive/UK/development/train_indiv.csv', index_col=0, engine='python', error_bad_lines=False)\n",
    "train = train.sample(frac=1)\n",
    "train_label = train['Label'].copy().values\n",
    "train_sents = train['CTweet'].copy().values\n",
    "w = train.Label.value_counts(normalize=True)\n",
    "weights ={0:1/w[0], 1:1/w[1]}\n",
    "print(weights)\n",
    "#weights={0:1, 1:14}\n",
    "print(weights)\n",
    "train\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) # english, spanish, french, italian, german\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rLiRQ5Ii415"
   },
   "source": [
    "Define final cleaning and sparisty reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "1da71938e53a46659a1ecd222c323bb3",
      "322b5d3edf5c4f0fa216e96c1dbc8dc0",
      "41265e1b9308415f87febc09092da832",
      "29820da486d44b7bac559b17815d724c",
      "ca6b42bb283e423bbd88daeb967643f2",
      "59503a1bf8e94c11afe160053e23bea9",
      "a3875670829840579d61557f40230484",
      "3572bedfe8164095a8e10fd5867d2169",
      "7f5606860ec741b8bee330f55c55a7da",
      "14a98470c3c64a6383ad121849921a7f",
      "28efddc5c61449dca4daf3399b823cb2",
      "ecebcdc00dd0452d884f79550b85062c",
      "ac797533301f4ed998455697aeb27dc3",
      "6c7b924dc60042efa28c87c287c9bf5d",
      "e53f57c8cb314561a4194e9eee71c2ca",
      "4e703333f12f48c69d6416ddaa97eef8"
     ]
    },
    "colab_type": "code",
    "id": "7744z70or8-G",
    "outputId": "066fd190-3db7-4c0b-dab8-8dd20b344c5b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da71938e53a46659a1ecd222c323bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2887060.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5606860ec741b8bee330f55c55a7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2887060.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.HASHTAG)\n",
    "\n",
    "def clean(tweets, min_occurence):\n",
    "   #########\n",
    "  vocab_freq = {'<PAD>':min_occurance,'<UNK>':min_occurance}\n",
    "\n",
    "  for tweet in tqdm(tweets):\n",
    "    tokenized = tweet.split(' ')\n",
    "    for word in tokenized:\n",
    "      if word not in vocab_freq.keys():\n",
    "        vocab_freq[word] = 1\n",
    "      else:\n",
    "        vocab_freq[word]+=1\n",
    "\n",
    "  recons_sent = []\n",
    "  for tweet in tqdm(tweets):\n",
    "    tokenized = tweet.split(' ')\n",
    "    new_sent = []\n",
    "    for word in tokenized:\n",
    "      if word not in vocab_freq.keys() or vocab_freq[word] <min_occurance or word in stop_words or word.isdigit():\n",
    "        new_sent.append('<UNK>')\n",
    "      else:\n",
    "        new_sent.append(word)\n",
    "    recons_sent.append(new_sent)\n",
    "  return recons_sent, vocab_freq\n",
    "\n",
    "min_occurance =10\n",
    "recons_sent, vocab_freq = clean(train_sents, min_occurence=min_occurance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4Te5W1ajHIy"
   },
   "source": [
    "RAM boosting for google colab (increases RAM from 16GB to 25GB), vocabulary definition and sentence numerizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "w0Uo-ulKoncj",
    "outputId": "f1e81921-ef4c-4cc6-b3b7-ba3e0c9e59c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64547\n",
      "maxlen 131\n"
     ]
    }
   ],
   "source": [
    "def boost_ram():\n",
    "  a = []\n",
    "  while(1):\n",
    "    a.append('1')\n",
    "\n",
    "#boost_ram()\n",
    "\n",
    "final_vocab =[key for key, val in vocab_freq.items() if val >=min_occurance]\n",
    "ids_to_word = {ind:word for ind, word in enumerate(final_vocab)}\n",
    "word_to_ids = {word:ind for ind, word in enumerate(final_vocab)}\n",
    "\n",
    "numerized_sent = np.array([np.array([word_to_ids[word] for word in tweet]) for tweet in recons_sent]) #.transpose inside\n",
    "print(len(final_vocab))\n",
    "\n",
    "maxlen=len(max(numerized_sent, key=len))\n",
    "for ind, row in enumerate(numerized_sent):\n",
    "  if len(row)==maxlen:\n",
    "    final = ind\n",
    "\n",
    "print('maxlen', maxlen)\n",
    "#train.iloc[final]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-Z07Mllnes5"
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "6E8axaw1hAbM",
    "outputId": "0d1a60a3-b1dd-4b47-c998-f8591f991d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None', 'Depressed'}\n",
      "0.08017533407688097\n",
      "[0 1]\n",
      "<class 'numpy.ndarray'> 115850 {'None', 'Depressed'}\n",
      "0.4987570133793699\n",
      "[0 1]\n",
      "* 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n\\nexp = pd.read_csv(exp_path, index_col=0, encoding='utf8', engine='python', error_bad_lines=False)\\nexp_sent = exp['CTweet'].copy().values\\nprint(exp)\\nprint(exp.columns)\\nrecons_sent_exp=[]\\nfor tweet in exp_sent:\\n  tokenized = tweet.split(' ')  \\n  new_sent = []\\n  for word in tokenized:\\n    if word not in vocab_freq.keys() or vocab_freq[word] <min_occurance or word in stop_words or word.isdigit():\\n      new_sent.append('<UNK>')\\n    else:\\n      new_sent.append(word)\\n  recons_sent_exp.append(new_sent)\\nnumerized_exp =np.array([np.array([word_to_ids[word] for word in tweet]) for tweet in recons_sent_exp])\""
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####uncomment numerized test\n",
    "###from keras.utils import to_categorical\n",
    "def labels(labs, t = None):\n",
    "  lab = []\n",
    "  pos=0\n",
    "  if t == 'time':\n",
    "    for l in labs:\n",
    "      l = list(l)\n",
    "      if 'D' in l:\n",
    "        pos+=1\n",
    "        lab.append(1)\n",
    "      else:\n",
    "        lab.append(0)\n",
    "    print(pos/len(lab))\n",
    "    return (np.array(lab)).astype(int)\n",
    "\n",
    "  else:\n",
    "    if 'Depressed' in labs:\n",
    "      print('inside')\n",
    "    #return pd.get_dummies(df.Label).reset_index(drop=True)\n",
    "    \n",
    "    for i in labs:\n",
    "      if i =='Depressed':\n",
    "        lab.append(1)\n",
    "      else:\n",
    "        lab.append(0)\n",
    "    return (np.array(lab)).astype(int)\n",
    "\n",
    "print(set(train_label))\n",
    "train_labels = labels(train_label, t ='time')\n",
    "#print(np.shape(train_labels))\n",
    "#print(set(train_labels))\n",
    "print(np.unique(train_labels))\n",
    "\n",
    "def custom_round(i):\n",
    "  if i >=0.5:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "#print(set([custom_round(p) for p in model.predict(X_train)]))\n",
    "\n",
    "\n",
    "test = pd.read_csv(test_path, index_col=0, encoding='utf8', engine='python', error_bad_lines=False)\n",
    "test_label = test['Label'].copy().values\n",
    "test_sent = test['CTweet'].copy().values\n",
    "print(type(test_label), len(test_label), set(test_label))\n",
    "test_labels =labels(test_label, t='time')\n",
    "print(np.unique(test_labels))\n",
    "\n",
    "num_list, num_freq = np.unique(test_labels)\n",
    "print('*', num_freq)\n",
    "\n",
    "recons_sent_test=[]\n",
    "for tweet in test_sent:\n",
    "  tokenized = tweet.split(' ')\n",
    "  new_sent = []\n",
    "  for word in tokenized:\n",
    "    if word not in vocab_freq.keys() or vocab_freq[word] <min_occurance or word in stop_words or word.isdigit():\n",
    "      new_sent.append('<UNK>')\n",
    "    else:\n",
    "      new_sent.append(word)\n",
    "  recons_sent_test.append(new_sent)\n",
    "numerized_test =np.array([np.array([word_to_ids[word] for word in tweet]) for tweet in recons_sent_test]) ### comment this for bert to save ram\n",
    "'''\n",
    "\n",
    "exp = pd.read_csv(exp_path, index_col=0, encoding='utf8', engine='python', error_bad_lines=False)\n",
    "exp_sent = exp['CTweet'].copy().values\n",
    "print(exp)\n",
    "print(exp.columns)\n",
    "recons_sent_exp=[]\n",
    "for tweet in exp_sent:\n",
    "  tokenized = tweet.split(' ')  \n",
    "  new_sent = []\n",
    "  for word in tokenized:\n",
    "    if word not in vocab_freq.keys() or vocab_freq[word] <min_occurance or word in stop_words or word.isdigit():\n",
    "      new_sent.append('<UNK>')\n",
    "    else:\n",
    "      new_sent.append(word)\n",
    "  recons_sent_exp.append(new_sent)\n",
    "numerized_exp =np.array([np.array([word_to_ids[word] for word in tweet]) for tweet in recons_sent_exp])'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YsXRRR0Qkk6K"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQXLhm6ukx4P"
   },
   "source": [
    "Padding samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "b7hKGF7EhM4s",
    "outputId": "463d7762-5fa7-4dd3-b49f-da84c7bf49fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13721116482753433012, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 17931792607867235859\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 18180536153470192801\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 15695549568\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8766724516183252397\n",
       " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "#ohe_labels = ohe.fit_transform(train_labels)\n",
    "MAXLENGTH=120\n",
    "#120 indiv\n",
    "#X_exp = keras.preprocessing.sequence.pad_sequences(numerized_exp, maxlen=MAXLENGTH, padding='post', value=0)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(numerized_test, maxlen=MAXLENGTH, padding='post', value=0)\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(numerized_sent, maxlen=MAXLENGTH, padding='post', value=0)#, keras.preprocessing.sequence.pad_sequences(numerized_test, maxlen=MAXLENGTH, padding='post', value=0)\n",
    "#print('done padding')\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NHKCRcJ0ftT"
   },
   "source": [
    "## Variety of fully Connected-based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "colab_type": "code",
    "id": "-jUifIdshhD0",
    "outputId": "18f93fc6-4bef-45d4-da29-21cb76e2b132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 300)         120000300 \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 120,333,001\n",
      "Trainable params: 120,333,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 300)         120000300 \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 120,333,001\n",
      "Trainable params: 120,333,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "371/371 [==============================] - 259s 699ms/step - loss: 0.6059 - accuracy: 0.6489 - val_loss: 0.5599 - val_accuracy: 0.6916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2dabc2f550>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv2D,Conv1D, Dropout, Reshape, BatchNormalization, MaxPool2D, TimeDistributed, Flatten, Input, Concatenate, Bidirectional, GRU, LSTM\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import keras\n",
    "\n",
    "\n",
    "embedding_size=100\n",
    "vocab_size=len(final_vocab)+1\n",
    "cnt=0\n",
    "len_array =[]\n",
    "for ind, row in enumerate(numerized_sent):\n",
    "  len_array.append(len(list(row)))\n",
    "  if int(len(list(row)))>cnt:\n",
    "    cnt=len(row)\n",
    "    i=ind\n",
    "\n",
    "print(len(recons_sent[i]))\n",
    "\n",
    "\n",
    "def readGloveFile(gloveFile):\n",
    "    with open(gloveFile, 'r') as f:\n",
    "        wordToGlove = {}  \n",
    "        wordToIndex = {}  \n",
    "        indexToWord = {}  \n",
    "\n",
    "        for line in f:\n",
    "            record = line.strip().split()\n",
    "            token = record[0] \n",
    "            wordToGlove[token] = np.array(record[1:], dtype=np.float64) \n",
    "            \n",
    "        tokens = sorted(wordToGlove.keys())\n",
    "        for idx, tok in enumerate(tokens):\n",
    "            kerasIdx = idx + 1  \n",
    "            wordToIndex[tok] = kerasIdx \n",
    "            indexToWord[kerasIdx] = tok \n",
    "\n",
    "    return wordToIndex, indexToWord, wordToGlove\n",
    "  \n",
    "from keras.initializers import Constant\n",
    "def createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable):\n",
    "    vocabLen = len(wordToIndex) + 1  \n",
    "    embDim = next(iter(wordToGlove.values())).shape[0]  \n",
    "   \n",
    "    embeddingMatrix = np.zeros((vocabLen, embDim))  \n",
    "    for word, index in wordToIndex.items():\n",
    "        embeddingMatrix[index, :] = wordToGlove[word] \n",
    "\n",
    "    embeddingLayer = keras.layers.Embedding(vocabLen, embDim, embeddings_initializer=Constant(embeddingMatrix), trainable=isTrainable)\n",
    "    return embeddingLayer\n",
    "\n",
    "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
    "    def call(self, x, mask=None):\n",
    "        if mask != None:\n",
    "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
    "        else:\n",
    "            return super().call(x)\n",
    "\n",
    "\n",
    "def glove_model():\n",
    "  #!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "  import zipfile\n",
    "  import os\n",
    "  path = 'glove.6B.zip'\n",
    "  directory = os.getcwd()\n",
    "  zipfile_ = zipfile.ZipFile(path, 'r')\n",
    "  zipfile_.extractall(directory)\n",
    "  zipfile_.close()\n",
    "  wordToIndex, indexToWord, wordToGlove = readGloveFile('glove.6B.300d.txt')\n",
    "  model_glove = keras.Sequential()\n",
    "  model_glove.add(createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable=True))\n",
    "  #model_glove.add(GlobalAveragePooling1DMasked())\n",
    "  model_glove.add(Bidirectional(LSTM(embedding_size)))\n",
    "  #model_glove.add(keras.layers.Dense(256, activation='relu'))###\n",
    "  #model_glove.add(keras.layers.Dense(128, activation='relu'))###\n",
    "  #model_glove.add(keras.layers.Dense(64, activation='relu'))###\n",
    "  #model_glove.add(keras.layers.Dense(16, activation='relu'))\n",
    "  model_glove.add(Dense(50, activation='relu'))\n",
    "  model_glove.add(Dense(30, activation='relu'))\n",
    "  model_glove.add(Dense(10, activation='relu'))\n",
    "  model_glove.add(Dense(1, activation='sigmoid'))\n",
    "  model_glove.summary()\n",
    "  model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "  return model_glove\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def trip_cnn_bi_aux_model():\n",
    "  inp = Input(shape=(MAXLENGTH, ), dtype='int32')\n",
    "  embedding = Embedding(vocab_size, embedding_size)(inp)\n",
    "  reshape = Reshape((MAXLENGTH, embedding_size,1))(embedding)\n",
    "  con1 = Conv2D(1, kernel_size=(1,embedding_size), strides=1, padding='valid')(reshape)\n",
    "  bn1 = BatchNormalization()(con1)\n",
    "  mxpl1 = MaxPool2D(pool_size=(MAXLENGTH-3+1, 1), padding='valid')(bn1)\n",
    "\n",
    "  con2 = Conv2D(1, kernel_size=(2,embedding_size), strides=1, padding='valid')(reshape)\n",
    "  bn2 = BatchNormalization()(con2)\n",
    "  mxpl2 = MaxPool2D(pool_size=(MAXLENGTH-3+1, 1), padding='valid')(bn2)\n",
    "\n",
    "  con3 = Conv2D(1, kernel_size=(3,embedding_size), strides=1, padding='valid')(reshape)\n",
    "  bn3 = BatchNormalization()(con3)\n",
    "  mxpl3 = MaxPool2D(pool_size=(MAXLENGTH-3+1, 1), padding='valid')(bn3)\n",
    "\n",
    "  #con4 = Conv2D(1, kernel_size=(4,embedding_size), strides=1, padding='valid')(reshape)\n",
    "  #bn4 = BatchNormalization()(con4)\n",
    "  #mxpl4 = MaxPool2D(pool_size=(MAXLENGTH-3+1, 1), padding='valid')(bn4)\n",
    "\n",
    "  #con5 = Conv2D(1, kernel_size=(5,embedding_size), strides=1, padding='valid')(reshape)\n",
    "  #bn5 = BatchNormalization()(con5)\n",
    "  #mxpl5 = MaxPool2D(pool_size=(MAXLENGTH-3+1, 1), padding='valid')(bn5)\n",
    "\n",
    "  conc = Concatenate()([mxpl1, mxpl2, mxpl3])#, mxpl4])#, mxpl5])\n",
    "  flat=TimeDistributed(Flatten())(conc)\n",
    "\n",
    "  #aux_dns1 = Dense(100, activation='relu')(flat)\n",
    "  #aux_drop1 = Dropout(0.5)(aux_dns1)\n",
    "  #aux_out1 = Dense(1, activation='sigmoid', name='aux1')(aux_drop1)\n",
    "\n",
    "  dense = Dense(100, activation='relu')(flat)\n",
    "\n",
    "  #bi = Bidirectional(LSTM(100, dropout=0.5))(dense)\n",
    "\n",
    "  #aux_dns2 = Dense(100, activation='relu')(dense)\n",
    "  #aux_drop2 = Dropout(0.5)(aux_dns2)\n",
    "  #aux_out2 = Dense(1, activation='sigmoid',name ='aux2')(aux_drop2)\n",
    "\n",
    "  FC1 = Dense(50, activation='relu')(dense)\n",
    "  FC2 = Dense(20, activation='relu')(FC1)\n",
    "  FC3 = Dense(10, activation='relu')(FC2)\n",
    "\n",
    "  out = Dense(1, activation='sigmoid', name='out')(FC3)\n",
    "\n",
    "  model=Model(inputs=[inp], outputs=[out])#, aux_out1, aux_out2])\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics =['accuracy'])\n",
    "  return model\n",
    "\n",
    "model = trip_cnn_bi_aux_model()\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "#model.add((LSTM(embedding_size)))#, return_sequences=True)))\n",
    "#model.add(Bidirectional(LSTM(embedding_size)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics =['accuracy'])\n",
    "'''\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size))\n",
    "#model.add(Bidirectional(LSTM(embedding_size)))\n",
    "model.add(Reshape((MAXLENGTH, embedding_size,1)))\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "\n",
    "#model.add(Conv2D(3, kernel_size=(3,embedding_size), strides=1, padding='valid'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(MaxPool2D(pool_size=(MAXLENGTH-3+1, 1), padding='valid'))\n",
    "#model.add(TimeDistributed(Flatten()))\n",
    "model.add(Conv2D(3, kernel_size=(3,embedding_size), strides=1, padding='valid'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(MAXLENGTH-3+1, 1), padding='valid'))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "#model.add(Bidirectional(LSTM(embedding_size)))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model =glove_model()\n",
    "\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics =['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train, train_labels, epochs=1, verbose=1, validation_split=0.2, batch_size=1000)#, class_weight={0:1, 1:5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G_tTjUdflE61"
   },
   "source": [
    "Classification report and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "QCnmFh6qHk_H",
    "outputId": "4c8c31db-f984-4e59-9b19-99744fa62b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.72      0.63      0.67     58069\n",
      "   Depressed       0.67      0.75      0.71     57781\n",
      "\n",
      "    accuracy                           0.69    115850\n",
      "   macro avg       0.69      0.69      0.69    115850\n",
      "weighted avg       0.69      0.69      0.69    115850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def custom_round(i, threshold=0.5):\n",
    "  if i >=threshold:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "predictions=model.predict(X_test, batch_size=1000)\n",
    "y_hat = [custom_round(p) for p in predictions]\n",
    "\n",
    "print(classification_report(test_labels, y_hat, target_names=['None', 'Depressed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPhBUN3dlK8W"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbmkD0hIHDiN"
   },
   "source": [
    "### Check Visualization of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "lRVGbFkZGyXC",
    "outputId": "de6c0f52-1b95-4bf2-ea13-1db338685a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18625, 100)\n",
      "                0         1         2   ...        97        98        99\n",
      "<PAD>     0.011321 -0.005494  0.020488  ...  0.002889  0.009385  0.027958\n",
      "<UNK>     0.002948 -0.061496  0.174171  ...  0.013947 -0.026549 -0.084553\n",
      "<S>      -0.033666  0.001576 -0.000170  ... -0.025770 -0.034647 -0.049544\n",
      "this     -0.039185  0.020004  0.031580  ...  0.122234  0.069560 -0.096166\n",
      "guy      -0.033033  0.049557  0.008694  ... -0.016146 -0.043799  0.049557\n",
      "is       -0.030162  0.002073 -0.043336  ... -0.015279 -0.023912  0.044554\n",
      "an       -0.259407  0.156951 -0.061572  ...  0.099361  0.148202 -0.044986\n",
      "absolute -0.198333  0.154463 -0.117272  ...  0.218285  0.111009 -0.164222\n",
      "child     0.007266  0.007618  0.029177  ... -0.045307 -0.015034  0.043124\n",
      "why      -0.069375  0.135140  0.008301  ...  0.184268 -0.042096 -0.016534\n",
      "\n",
      "[10 rows x 100 columns]\n",
      "(18625, 18625)\n",
      "{'depressed': ['sausage', 'trending', 'sexual', 'journalists', 'geeks', 'lent', '(yes', 'freeman', 'animation'], 'depression': ['db', 'xx', 'mum', 'bir', 'cat', 'ูุง', 'worcestershire', 'pig', 'xxx'], 'happy': ['friendly', 'flying', 'fitness', 'psychological', 'genuinely', 'ignorant', 'heading', 'eating', 'talking'], ':)': ['decade', 'ps', 'babe', 'possible', 'booked', 'gb', 'lord', 'quick', 'weak'], ':(': ['paper', 'list', 'especially', 'considering', 'session', 'se', 'photographer', 'parties', 'view'], 'diagnosed': ['fuckcancer', 'ani', 'dorset', 'bgt', 'shay', 'bpd', 'scooby', 'myart', 'ku'], 'sad': ['indeed', 'website', 'minutes', 'exciting', 'happen', 'global', 'course', 'link', 'itv'], 'dark': ['wembley', 'pakistan', 'china', 'bay', 'mystery', 'cc', 'favorite', 'cricket', 'committee'], 'upset': ['celebrating', 'fitness', 'wearing', 'fighting', 'delighted', 'heading', 'memorial', 'blood', 'jealous'], 'thrilled': ['delighted', 'struggling', 'afraid', 'convinced', 'beginning', 'surprised', 'joking', 'livid', 'jealous'], 'today': ['encouraged', 'drive', 'usually', 'hotel', 'man', 'works', 'funny', 'friends', 'honour'], 'random': ['peckham', 'wear', 'procrastinating', 'sophia', 'snooker', 'adopting', 'basics', 'either', 'former'], 'i': ['wanderers', 'pp', 'barnes', 'courts', 'submissions', 'collingwood', 'abroad', 'dripping', 'racism'], 'football': ['brexit', 'green', 'real', 'arts', 'palace', 'st', 'mate', 'safe', 'nyc']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "word_embeddings = model.get_layer('embedding_2').get_weights()[0][1:]\n",
    "\n",
    "# Sanity Check\n",
    "print(word_embeddings.shape)\n",
    "print(pd.DataFrame(word_embeddings, index=ids_to_word.values()).head(10))\n",
    "\n",
    "similarity_matrix = cosine_similarity(word_embeddings)\n",
    "\n",
    "# Check\n",
    "print(similarity_matrix.shape)\n",
    "\n",
    "\n",
    "search_items = ['depressed', 'depression', 'happy', ':)', ':(', 'diagnosed', 'sad', 'dark', 'upset', 'thrilled', 'today', 'random', 'i', 'football']\n",
    "similar_words = {term: [ids_to_word[idx] for idx in (-1 * similarity_matrix[word_to_ids[term]-1]).argsort()[1:10] + 1]\n",
    "                 for term in search_items}\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "Z-Tdd_EwG0Rd",
    "outputId": "4098cd7b-dfd3-41e7-cb11-aaff7fdc1118"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tsne = TSNE(perplexity=3, n_components=5, init='pca', n_iter=10000, method='exact')\n",
    "plot_only = len(search_items)\n",
    "T = tsne.fit_transform(word_embeddings[:plot_only, :])\n",
    "labels = [ids_to_word[i+1] for i in range(plot_only)]\n",
    "labels = search_items\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(T[:, 0], T[:, 1])\n",
    "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), \n",
    "                 textcoords='offset points', ha='right',va='bottom')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O5hcnTDh0m0y"
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5S1VzL7HlCh"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "S8N_PUCAblq3",
    "outputId": "76ae1fea-dced-4fe4-e878-280c9b5a0d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.5049039 ]]\n",
      "\n",
      " [[0.50697434]]\n",
      "\n",
      " [[0.5050979 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.50587153]]\n",
      "\n",
      " [[0.5054535 ]]\n",
      "\n",
      " [[0.5079675 ]]]\n",
      "{1}\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "def custom_round(i, t=None):\n",
    "  if t == 'list':\n",
    "    i = i[0]\n",
    "  if i >=0.5:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "y_hat = [custom_round(p) for p in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "BrhW8gyLfQQK",
    "outputId": "54a907ec-bc9c-4490-99a2-93ecbd78e40f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.00      0.00      0.00      1403\n",
      "   Depressed       0.07      1.00      0.12       100\n",
      "\n",
      "    accuracy                           0.07      1503\n",
      "   macro avg       0.03      0.50      0.06      1503\n",
      "weighted avg       0.00      0.07      0.01      1503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(test_labels[0])\n",
    "print(classification_report(test_labels, y_hat, target_names=['None', 'Depressed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5miNz1blvzW"
   },
   "source": [
    "## Bi/LSTM Model experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "BAY0CFPPJLo4",
    "outputId": "2ada9666-d175-4db6-8f4b-147b1360d854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         2211900   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,384,601\n",
      "Trainable params: 2,384,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "418/418 - 33s - loss: 0.5974 - accuracy: 0.6583 - val_loss: 0.5504 - val_accuracy: 0.6987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4530445668>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "embedding_size=100\n",
    "vocab_size=len(final_vocab)+1\n",
    "\n",
    "s_model= Sequential()\n",
    "s_model.add(Embedding(vocab_size, embedding_size))\n",
    "#s_model.add(LSTM(embedding_size, return_sequences=True))\n",
    "s_model.add(Bidirectional(LSTM(embedding_size)))\n",
    "s_model.add(Dense(50, activation='relu'))\n",
    "s_model.add(Dense(30, activation='relu'))\n",
    "s_model.add(Dense(10, activation='relu'))\n",
    "s_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "s_model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics =['accuracy'])\n",
    "s_model.summary()\n",
    "s_model.fit(X_train, train_labels, epochs=1, verbose=2, validation_split=0.1, batch_size=1000)#, class_weight=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "tcZJKJCZxa45",
    "outputId": "b5aa4b1b-bd86-4f08-f3c8-983c544a787d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "[0.9936063]\n",
      "0\n",
      "inside\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.69      0.72      0.70     58069\n",
      "   Depressed       0.70      0.67      0.69     57781\n",
      "\n",
      "    accuracy                           0.70    115850\n",
      "   macro avg       0.70      0.70      0.70    115850\n",
      "weighted avg       0.70      0.70      0.70    115850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = s_model.predict(X_test)\n",
    "def custom_round(i):\n",
    "  if i >=0.5:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "y_hat = [custom_round(p) for p in predictions]\n",
    "print(set(y_hat))\n",
    "print(max(predictions))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(test_labels[0])\n",
    "test_labels = labels(test_label)\n",
    "print(classification_report(test_labels, y_hat, target_names=['None', 'Depressed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ln_ECKLY0vvq"
   },
   "source": [
    "## Attention models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "PXXjElQCZWu5",
    "outputId": "16c43330-7cd7-4488-b4b0-50d493cebf41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 100)    2211900     input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 100)    10100       embedding_4[0][0]                \n",
      "                                                                 embedding_4[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, None, 100)    0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 100)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 100)          0           attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 1)            201         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,222,201\n",
      "Trainable params: 2,222,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 0.6112 - accuracy: 0.6403 - val_loss: 0.5615 - val_accuracy: 0.6934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f44c802a9e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Attention, Conv1D, Concatenate, Embedding\n",
    "import tensorflow as tf\n",
    "weights_new = {0:1, 1:5}\n",
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "query_input = Input(shape=(None,), dtype='int32')\n",
    "value_input = Input(shape=(None,), dtype='int32')\n",
    "\n",
    "token_embeddings = Embedding(vocab_size, embedding_size)#, embeddings_initializer='glorot_uniform')\n",
    "query_embeddings = token_embeddings(query_input)\n",
    "value_embeddings = token_embeddings(value_input)\n",
    "\n",
    "cnn_layer = Conv1D(filters=100, kernel_size=1, padding='same')#og filters=100, kernel_size=4\n",
    "lstm_layer = Bidirectional(LSTM(embedding_size, return_sequences=True))\n",
    "query_seq_encoding = cnn_layer(query_embeddings)\n",
    "value_seq_encoding = cnn_layer(value_embeddings)\n",
    "\n",
    "qv_attention_seq = Attention()([query_seq_encoding, value_seq_encoding])\n",
    "\n",
    "\n",
    "query_encoding = GlobalAveragePooling1D()(query_seq_encoding)\n",
    "query_value_attention = GlobalAveragePooling1D()(qv_attention_seq)\n",
    "\n",
    "conc = Concatenate()([query_encoding, query_value_attention])\n",
    "\n",
    "'''dns1 = Dense(50, activation='relu')(conc)\n",
    "dns2 = Dense(20, activation='relu')(dns1)\n",
    "dns3 = Dense(10, activation='relu')(dns2)\n",
    "'''\n",
    "output = Dense(1, activation='sigmoid', name='out')(conc)\n",
    "\n",
    "model2 = Model(inputs = [query_input, value_input], outputs=[output])\n",
    "model2.compile(loss = 'binary_crossentropy', optimizer='adam', metrics =['accuracy'])\n",
    "\n",
    "model2.summary()\n",
    "model2.fit([X_train, X_train],train_labels, epochs=1, verbose=1, validation_split=0.1, batch_size=1000)#, class_weight=weights_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "cPHtx4ELFlkn",
    "outputId": "ca373883-c683-4d18-f7a4-92f400f5d124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.69      0.70      0.70     58069\n",
      "   Depressed       0.70      0.68      0.69     57781\n",
      "\n",
      "    accuracy                           0.69    115850\n",
      "   macro avg       0.69      0.69      0.69    115850\n",
      "weighted avg       0.69      0.69      0.69    115850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def custom_round(i, threshold=0.5):\n",
    "  if i >=threshold:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "predictions=model2.predict([X_test, X_test], batch_size=1000)\n",
    "y_hat = [custom_round(p) for p in predictions]\n",
    "\n",
    "print(classification_report(test_labels, y_hat, target_names=['None', 'Depressed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8BT26KpmFg_"
   },
   "source": [
    "## Self Attention Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "colab_type": "code",
    "id": "ifSt-8DI2150",
    "outputId": "23e03b57-f9e6-4344-eb0a-2f9b4e5d82b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-self-attention\n",
      "  Downloading https://files.pythonhosted.org/packages/39/0d/b8ab8469ae55cea199574f4d2c30da4656d310a833a67bb422ad8a056bf0/keras-self-attention-0.47.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.4.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n",
      "Building wheels for collected packages: keras-self-attention\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.47.0-cp36-none-any.whl size=17289 sha256=ff3f5df9510b7928fe6eea981951943303e94cdb7d0f47e346537aae89dc840e\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/87/01/76c703d5401b65e323927c1fdc665f3fb143282ff67d71e859\n",
      "Successfully built keras-self-attention\n",
      "Installing collected packages: keras-self-attention\n",
      "Successfully installed keras-self-attention-0.47.0\n",
      "Name: tensorflow\n",
      "Version: 2.3.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.6/dist-packages\n",
      "Requires: opt-einsum, gast, numpy, termcolor, astunparse, protobuf, wheel, h5py, tensorboard, wrapt, six, grpcio, scipy, absl-py, google-pasta, tensorflow-estimator, keras-preprocessing\n",
      "Required-by: fancyimpute\n",
      "Name: Keras\n",
      "Version: 2.4.3\n",
      "Summary: Deep Learning for humans\n",
      "Home-page: https://github.com/keras-team/keras\n",
      "Author: Francois Chollet\n",
      "Author-email: francois.chollet@gmail.com\n",
      "License: MIT\n",
      "Location: /usr/local/lib/python3.6/dist-packages\n",
      "Requires: h5py, scipy, pyyaml, numpy\n",
      "Required-by: textgenrnn, keras-vis, keras-self-attention, kapre, fancyimpute\n",
      "Collecting keras-multi-head\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-multi-head) (1.18.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-multi-head) (2.4.3)\n",
      "Collecting keras-self-attention==0.46.0\n",
      "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-multi-head) (1.15.0)\n",
      "Building wheels for collected packages: keras-multi-head, keras-self-attention\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15611 sha256=47cb1eff2c59cd5c72b39b4b8855fa02eafead4a3c3fd0c2681c941e6726d497\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=7ff6e03491e8a0e88aa0cace7514647f4755f2ec17cfa897d301803fead24de8\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
      "Successfully built keras-multi-head keras-self-attention\n",
      "Installing collected packages: keras-self-attention, keras-multi-head\n",
      "  Found existing installation: keras-self-attention 0.47.0\n",
      "    Uninstalling keras-self-attention-0.47.0:\n",
      "      Successfully uninstalled keras-self-attention-0.47.0\n",
      "Successfully installed keras-multi-head-0.27.0 keras-self-attention-0.46.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keras-self-attention\n",
    "!pip3 show tensorflow\n",
    "!pip3 show keras\n",
    "!pip3 install keras-multi-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "0EgHLniP28VK",
    "outputId": "8984bb32-eb79-421d-a395-b0e59c1f8233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 100)          6454800   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 120, 256)          234496    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_1 (SeqSel (None, None, 256)         16449     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1)           257       \n",
      "=================================================================\n",
      "Total params: 6,706,002\n",
      "Trainable params: 6,706,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2310/2310 [==============================] - 543s 235ms/step - loss: 0.7053 - accuracy: 0.8927 - val_loss: 0.3429 - val_accuracy: 0.9013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33e47cb128>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras_multi_head import MultiHead, MultiHeadAttention\n",
    "import keras\n",
    "new_weights = {0:1, 1:5}\n",
    "vector_size=120\n",
    "embedding_size=100\n",
    "vocab_size=len(final_vocab)+1\n",
    "\n",
    "sa_model = keras.models.Sequential()\n",
    "sa_model.add(keras.layers.Embedding(vocab_size, embedding_size, input_shape=(vector_size,), mask_zero=False))\n",
    "sa_model.add(keras.layers.Bidirectional(keras.layers.LSTM(128, \n",
    "                                                         return_sequences=True)))\n",
    "#sa_model.add(MultiHead(SeqSelfAttention(attention_activation='sigmoid')))\n",
    "sa_model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "#sa_model.add(keras.layers.Flatten())\n",
    "sa_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "'''input_key = keras.layers.Input(name='KeyInput', shape=(120,))\n",
    "input_value=keras.layers.Input(name='ValueInput', shape=(120,))\n",
    "#emb_query = keras.layers.Embedding(vocab_size, embedding_size, input_shape=(120,), name='QueryEmb')(input_query)\n",
    "emb_key=keras.layers.Embedding(vocab_size, embedding_size, input_shape=(120,), name='KeyEmb')(input_key)\n",
    "emb_value=keras.layers.Embedding(vocab_size, embedding_size, input_shape=(120,), name='ValueEmb')(input_value)\n",
    "enc_block = encoder1_block([emb_query, emb_key, emb_value])\n",
    "dns1=keras.layers.Dense(10, activation='relu')(enc_block)\n",
    "out=keras.layers.Dense(1, activation='sigmoid')(dns1)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "input_query= keras.layers.Input(name='QueryInput', shape=(vector_size,))\n",
    "input_key = keras.layers.Input(name='KeyInput', shape=(vector_size,))\n",
    "input_value=keras.layers.Input(name='ValueInput', shape=(vector_size,))\n",
    "emb_query = keras.layers.Embedding(vocab_size, embedding_size, input_shape=(vector_size,), name='QueryEmb')(input_query)\n",
    "emb_key=keras.layers.Embedding(vocab_size, embedding_size, input_shape=(vector_size,), name='KeyEmb')(input_key)\n",
    "emb_value=keras.layers.Embedding(vocab_size, embedding_size, input_shape=(vector_size,), name='ValueEmb')(input_value)\n",
    "bilstm=keras.layers.Bidirectional(keras.layers.LSTM(embedding_size, return_sequences=True))\n",
    "\n",
    "cnn_layer1= keras.layers.Conv1D(filters=100, kernel_size=1, padding='same')\n",
    "cnn_layer2=keras.layers.Conv1D(filters=100, kernel_size=2, padding='same')\n",
    "cnn_layer3=keras.layers.Conv1D(filters=100, kernel_size=3, padding='same')\n",
    "batch_norm = keras.layers.BatchNormalization()\n",
    "dropout= keras.layers.Dropout(rate=0.5)\n",
    "att = MultiHeadAttention(head_num=2, name='MultiHeadAttention')([emb_query, emb_key, emb_value])\n",
    "#bi = bilstm([att])\n",
    "drop = dropout(att)\n",
    "lin=keras.layers.Dense(64, activation='relu')(drop)\n",
    "non_lin_att = SeqSelfAttention(attention_activation='sigmoid')(lin)\n",
    "\n",
    "#add dropouts\n",
    "#break linearity\n",
    "pool=keras.layers.GlobalMaxPooling1D()(non_lin_att)\n",
    "\n",
    "#flat=keras.layers.Flatten()(att)\n",
    "dns1 = keras.layers.Dense(10, activation='relu', name='FC')(pool)\n",
    "out=keras.layers.Dense(1, activation='sigmoid', name='Out')(dns1)\n",
    "sa_model=keras.models.Model(inputs=[input_query, input_key, input_value], outputs=[out])\n",
    "\n",
    "#sa_model=keras.models.Model(inputs=[input_key,input_value], outputs=[out])\n",
    "'''\n",
    "#adam = keras.optimizers.Adam(learning_rate=1)\n",
    "sa_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])#adam opt\n",
    "sa_model.summary()\n",
    "\n",
    "sa_model.fit(X_train,train_labels, epochs=1, verbose=1, validation_split=0.2, batch_size=1000, class_weight=new_weights)\n",
    "#sa_model.save('/content/drive/My Drive/UK/MHA_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "sFmcawXfrQT-",
    "outputId": "9bb3e16b-ab03-40ad-f71e-f9f1f8838aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0876310253581913, 1: 12.411483500421303}\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "keys , vals = np.unique(test_labels, return_counts=True)\n",
    "new_weights = {k:sum(vals)/v for k, v in zip(keys, vals)}\n",
    "print(new_weights)\n",
    "print(np.unique(test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kKqauD_mMKm"
   },
   "source": [
    "Definition of post-training tasks: get fine grained accuracies (get_accuracies: true positives, false positives, true negatives, true positives); annotate experiment/training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "OAD5TqWsHm0b",
    "outputId": "544ba9ce-c635-4244-e173-bf821ce5ceb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55770 2299 41080 16701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.58      0.96      0.72     58069\n",
      "   Depressed       0.88      0.29      0.44     57781\n",
      "\n",
      "    accuracy                           0.63    115850\n",
      "   macro avg       0.73      0.62      0.58    115850\n",
      "weighted avg       0.73      0.63      0.58    115850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def custom_round(i, threshold=0.5):\n",
    "\n",
    "  if i >=threshold:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "def certainty(i, threshold=0.5):\n",
    "  if threshold>0.5:\n",
    "    return abs(i-threshold)/(1-threshold)\n",
    "  else:\n",
    "    return abs(i-threshold)/threshold\n",
    "\n",
    "def get_accuracies():\n",
    "  predictions=sa_model.predict(X_test, batch_size=100)\n",
    "  y_hat = [custom_round(p[0]) for p in predictions]\n",
    "  tn, fp, fn, tp = confusion_matrix(test_labels, y_hat).ravel()\n",
    "  print(tn, fp, fn, tp)\n",
    "  print(classification_report(test_labels, y_hat, target_names=['None', 'Depressed']))\n",
    "\n",
    "def exp_annot():\n",
    "  predictions=sa_model.predict(X_exp, batch_size=100)\n",
    "  print(type(predictions))\n",
    "  print(predictions)\n",
    "  print(np.shape(predictions))\n",
    "  y_hat = [custom_round(p.mean()) for p in predictions]\n",
    "  print(set(y_hat))\n",
    "  #uncertainty = [certainty(i)[0] for i in predictions]\n",
    "  #exp['Sig_out'] = pd.Series([p for p in predictions], index=exp.index)\n",
    "  exp['predictions']= pd.Series(y_hat, index=exp.index)\n",
    "  #exp['certainty'] = pd.Series(uncertainty, index=exp.index)\n",
    "\n",
    "def test_annot():\n",
    "  predictions=sa_model.predict(X_test, batch_size=1000)\n",
    "  y_hat = [custom_round(p) for p in predictions]\n",
    "  print(set(y_hat))\n",
    "  uncertainty = [certainty(i)[0] for i in predictions]\n",
    "  test['Sig_out'] = pd.Series([p for p in predictions], index=test.index)\n",
    "  test['predictions']= pd.Series(y_hat, index=test.index)\n",
    "  test['certainty'] = pd.Series(uncertainty, index=test.index)\n",
    "\n",
    "get_accuracies()\n",
    "#exp_annot()\n",
    "#test_annot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAb08RgdzVsH"
   },
   "outputs": [],
   "source": [
    "000#exp\n",
    "#test.to_csv('/content/drive/My Drive/Germany/development/test_indiv_results.csv')\n",
    "#exp.to_csv('/content/drive/My Drive/Germany/experiment/indiv_exp_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9QpC9ERq1qk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#predictions = model2.predict([X_test, X_test])\n",
    "def custom_round(i, threshold=0.5):\n",
    "  if i >=threshold:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def certainty(i, threshold=0.5):\n",
    "  if threshold>0.5:\n",
    "    return abs(i-threshold)/(1-threshold)\n",
    "  else:\n",
    "    return abs(i-threshold)/threshold\n",
    "\n",
    "\n",
    "def certainty_in_pred(gt, pred, threshold=0.5):\n",
    "  tp_s, tn_s, fp_s, fn_s=0,0,0,0\n",
    "  tp_c, tn_c, fp_c, fn_c=0,0,0,0\n",
    "  tp_a, tn_a, fp_a, fn_a=[], [], [], []\n",
    "  res = []\n",
    "  for p, l in zip(pred, gt):\n",
    "    yhat = custom_round(p, threshold=threshold)\n",
    "    if l==0 and yhat==0:\n",
    "      tn_c+=1\n",
    "      tn_s+=p\n",
    "      tn_a.append(p)\n",
    "      res.append('TN')\n",
    "    elif l==0 and yhat==1:\n",
    "      fp_c+=1\n",
    "      fp_s+=p\n",
    "      fp_a.append(p)\n",
    "      res.append('FP')\n",
    "    elif l==1 and yhat==1:\n",
    "      tp_c+=1\n",
    "      tp_s+=p\n",
    "      tp_a.append(p)\n",
    "      res.append('TP')\n",
    "    elif l==1 and yhat==0:\n",
    "      fn_c+=1\n",
    "      fn_s+=p\n",
    "      fn_a.append(p)\n",
    "      res.append('FN')\n",
    "    else:\n",
    "      print('prob')\n",
    "  return {'TN':tn_s/tn_c, 'FN': fn_s/fn_c, 'TP': tp_s/tp_c, 'FP': fp_s/fp_c}, {'TN':np.std(tn_a), 'FN':np.std(fn_a), 'TP':np.std(tp_a), 'FP':np.std(fp_a)}, res\n",
    "  \n",
    "'''t=0.65\n",
    "#predictions=model2.predict([X_exp, X_exp])\n",
    "#predictions=model2.predict([X_test, X_test], batch_size=32)\n",
    "predictions=sa_model.predict([X_test, X_test, X_test], batch_size=1000)\n",
    "y_hat = [custom_round(p, threshold=t) for p in predictions]\n",
    "uncertainty = [certainty(i, threshold=t)[0] for i in predictions]\n",
    "print(uncertainty[:5])\n",
    "certainty_summary, certainty_std, res=certainty_in_pred(test_labels, predictions, threshold=t)\n",
    "print(set(y_hat))\n",
    "print('Certainry Summary')\n",
    "print(certainty_summary)\n",
    "print('Certainty Std Dev')\n",
    "print(certainty_std)\n",
    "predictions=[p for p in predictions]\n",
    "#train['prediction'] = pd.Series(y_hat, index=train.index) #indicies of below are train\n",
    "#train['Sig_out'] = pd.Series(predictions, index=train.index)\n",
    "#train['res'] = pd.Series(res, index=train.index)\n",
    "#train.to_csv('/content/drive/My Drive/UK/train_results_pred_sigout_res.csv')\n",
    "#exp['prediction'] = pd.Series(y_hat, index=exp.index)\n",
    "#exp['certainty']=pd.Series(uncertainty, index=exp.index)\n",
    "#exp.to_csv('/content/drive/My Drive/UK/exp_indiv_pred_w_cert.csv')\n",
    "\n",
    "print(classification_report(test_labels, y_hat, target_names=['None', 'Depressed']))'''\n",
    "\n",
    "predictions=sa_model.predict(X_train, batch_size=1000)\n",
    "y_hat = [custom_round(p) for p in predictions]\n",
    "uncertainty = [certainty(i)[0] for i in predictions]\n",
    "train['Sig_out'] = pd.Series([p for p in predictions], index=train.index)\n",
    "train['predictions']= pd.Series(y_hat, index=train.index)\n",
    "train['certainty'] = pd.Series(uncertainty, index=train.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15plkcr5xD7A"
   },
   "outputs": [],
   "source": [
    "train.to_csv('/content/drive/My Drive/UK/train_for_validation.csv')\n",
    "test.to_csv('/content/drive/My Drive/UK/test_for_validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFkVDJ8VnwRH"
   },
   "source": [
    "## Pretrained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "NDxFqsFM6gkR",
    "outputId": "ed7719ea-af0f-4c3f-fd17-a71a4cbce01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.12.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.18.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (49.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
      "Requirement already up-to-date: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.31.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (49.2.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow_hub\n",
    "!pip3 install tqdm\n",
    "!pip3 install --upgrade 'tensorflow==1.15.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246,
     "referenced_widgets": [
      "4f188ff0a1de40f88296e6869f3a7bd8",
      "842f84f31b0a41a7a2033c41c4ff0320",
      "248b5784fd7e43709a3b38c65773676a",
      "8bc7b0e3031c4c88ac448b3e4a71bf30",
      "7988457ea11843d3bd0856b2d9edf920",
      "5663ec248f124624950a0e3a78c152b3",
      "63e0bb67088f4491b61629cceb0423b4",
      "02cb4d8b7ba74ed583eb3cd2b5962075",
      "4ef21b6cdb8a47a0afd0c8995177dde3",
      "c0ce5ce0f73d499c96a2c69e83c149d3",
      "a47bbc12d641435ea1593975210db7ff",
      "8dc47736b1d249018659d3890711bcfb",
      "d253047755154c9fbe153445e14f6848",
      "7fd940c416b943a9b314e5ac0287639d",
      "41bf827d78e44b4dbc52b59217d6f772",
      "75579cd72f2641f1b4f84ae1a0bcbc8a"
     ]
    },
    "colab_type": "code",
    "id": "U-zwPsHYn0bl",
    "outputId": "ecce9e3a-31c2-460a-9ffa-e17eef8644f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f188ff0a1de40f88296e6869f3a7bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=463398.0, style=Proโฆ"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef21b6cdb8a47a0afd0c8995177dde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=115850.0, style=Proโฆ"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "max_seq_length = 120\n",
    "\n",
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "class InputExample(object):\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "\n",
    "    bert_module =  hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=120):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=120):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples\n",
    "\n",
    "# Task 1\n",
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "# Convert data to InputExample format\n",
    "InputExamplesTrain=convert_text_to_examples(recons_sent,train_labels)\n",
    "InputExamplesTest=convert_text_to_examples(recons_sent_test,test_labels)\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels) = convert_examples_to_features(tokenizer, InputExamplesTrain)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels) = convert_examples_to_features(tokenizer, InputExamplesTest)\n",
    "# End of Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZ7FEKgTTmCa"
   },
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "EQzgeEceTmpX",
    "outputId": "e6a25dae-ef7c-454f-be4e-db22172c9748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "# Build model\n",
    "\n",
    "print(np.unique(train_labels))\n",
    "\n",
    "input_ids = tf.keras.layers.Input((max_seq_length,), dtype='float32', name='IDInput')\n",
    "input_masks = tf.keras.layers.Input((max_seq_length,), dtype='float32', name='MASKSInput')\n",
    "input_segment_ids = tf.keras.layers.Input((max_seq_length,), dtype='float32', name='SEGMENTIDInput')\n",
    "major_input = [input_ids, input_masks, input_segment_ids]\n",
    "bert = BertLayer(n_fine_tune_layers=1)(major_input)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(bert)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[major_input], outputs = [output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# End of Task 2\n",
    "\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EztEDe4Au0uQ"
   },
   "outputs": [],
   "source": [
    "weights = {0:1, 1:11.46}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "colab_type": "code",
    "id": "_qlyBe6jG1U2",
    "outputId": "923301c4-453e-4cf2-ef39-afc72b520803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Train on 463398 samples\n",
      "463398/463398 [==============================] - 2220s 5ms/sample - loss: 0.6747 - acc: 0.5651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a1c0ca198>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights={0:1, 1:5}\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "print(np.unique(train_labels))\n",
    "print(type(train_input_ids), type(train_input_masks), type(train_segment_ids), type(train_labels))\n",
    "\n",
    "model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    epochs=1,\n",
    "    batch_size=100)\n",
    "    #, class_weight=weights\n",
    "\n",
    "#validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "y75Oj0cLZ5v_",
    "outputId": "22c4f559-b9d0-412a-f26a-b23e2ccb9c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.65      0.50      0.57     58069\n",
      "   Depressed       0.59      0.73      0.65     57781\n",
      "\n",
      "    accuracy                           0.61    115850\n",
      "   macro avg       0.62      0.61      0.61    115850\n",
      "weighted avg       0.62      0.61      0.61    115850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def custom_round(i):\n",
    "  if i >=0.5:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "predictions=model.predict([test_input_ids, test_input_masks, test_segment_ids], batch_size=100)\n",
    "y_hat = [custom_round(p) for p in predictions]\n",
    "\n",
    "print(classification_report(test_labels, y_hat, target_names=['None', 'Depressed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moaGYha76mMj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9NHKCRcJ0ftT",
    "PbmkD0hIHDiN",
    "t5miNz1blvzW",
    "ln_ECKLY0vvq"
   ],
   "machine_shape": "hm",
   "name": "exploring_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cb4d8b7ba74ed583eb3cd2b5962075": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14a98470c3c64a6383ad121849921a7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1da71938e53a46659a1ecd222c323bb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_41265e1b9308415f87febc09092da832",
       "IPY_MODEL_29820da486d44b7bac559b17815d724c"
      ],
      "layout": "IPY_MODEL_322b5d3edf5c4f0fa216e96c1dbc8dc0"
     }
    },
    "248b5784fd7e43709a3b38c65773676a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Converting examples to features: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5663ec248f124624950a0e3a78c152b3",
      "max": 463398,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7988457ea11843d3bd0856b2d9edf920",
      "value": 463398
     }
    },
    "28efddc5c61449dca4daf3399b823cb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c7b924dc60042efa28c87c287c9bf5d",
      "max": 2887060,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac797533301f4ed998455697aeb27dc3",
      "value": 2887060
     }
    },
    "29820da486d44b7bac559b17815d724c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3572bedfe8164095a8e10fd5867d2169",
      "placeholder": "โ",
      "style": "IPY_MODEL_a3875670829840579d61557f40230484",
      "value": " 2887060/2887060 [00:20&lt;00:00, 142810.79it/s]"
     }
    },
    "322b5d3edf5c4f0fa216e96c1dbc8dc0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3572bedfe8164095a8e10fd5867d2169": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41265e1b9308415f87febc09092da832": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59503a1bf8e94c11afe160053e23bea9",
      "max": 2887060,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca6b42bb283e423bbd88daeb967643f2",
      "value": 2887060
     }
    },
    "41bf827d78e44b4dbc52b59217d6f772": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e703333f12f48c69d6416ddaa97eef8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ef21b6cdb8a47a0afd0c8995177dde3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a47bbc12d641435ea1593975210db7ff",
       "IPY_MODEL_8dc47736b1d249018659d3890711bcfb"
      ],
      "layout": "IPY_MODEL_c0ce5ce0f73d499c96a2c69e83c149d3"
     }
    },
    "4f188ff0a1de40f88296e6869f3a7bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_248b5784fd7e43709a3b38c65773676a",
       "IPY_MODEL_8bc7b0e3031c4c88ac448b3e4a71bf30"
      ],
      "layout": "IPY_MODEL_842f84f31b0a41a7a2033c41c4ff0320"
     }
    },
    "5663ec248f124624950a0e3a78c152b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59503a1bf8e94c11afe160053e23bea9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63e0bb67088f4491b61629cceb0423b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c7b924dc60042efa28c87c287c9bf5d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75579cd72f2641f1b4f84ae1a0bcbc8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7988457ea11843d3bd0856b2d9edf920": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7f5606860ec741b8bee330f55c55a7da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28efddc5c61449dca4daf3399b823cb2",
       "IPY_MODEL_ecebcdc00dd0452d884f79550b85062c"
      ],
      "layout": "IPY_MODEL_14a98470c3c64a6383ad121849921a7f"
     }
    },
    "7fd940c416b943a9b314e5ac0287639d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "842f84f31b0a41a7a2033c41c4ff0320": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bc7b0e3031c4c88ac448b3e4a71bf30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02cb4d8b7ba74ed583eb3cd2b5962075",
      "placeholder": "โ",
      "style": "IPY_MODEL_63e0bb67088f4491b61629cceb0423b4",
      "value": " 463398/463398 [02:50&lt;00:00, 2723.32it/s]"
     }
    },
    "8dc47736b1d249018659d3890711bcfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75579cd72f2641f1b4f84ae1a0bcbc8a",
      "placeholder": "โ",
      "style": "IPY_MODEL_41bf827d78e44b4dbc52b59217d6f772",
      "value": " 115850/115850 [00:47&lt;00:00, 2463.97it/s]"
     }
    },
    "a3875670829840579d61557f40230484": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a47bbc12d641435ea1593975210db7ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Converting examples to features: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fd940c416b943a9b314e5ac0287639d",
      "max": 115850,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d253047755154c9fbe153445e14f6848",
      "value": 115850
     }
    },
    "ac797533301f4ed998455697aeb27dc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c0ce5ce0f73d499c96a2c69e83c149d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca6b42bb283e423bbd88daeb967643f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d253047755154c9fbe153445e14f6848": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e53f57c8cb314561a4194e9eee71c2ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecebcdc00dd0452d884f79550b85062c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e703333f12f48c69d6416ddaa97eef8",
      "placeholder": "โ",
      "style": "IPY_MODEL_e53f57c8cb314561a4194e9eee71c2ca",
      "value": " 2887060/2887060 [00:33&lt;00:00, 85841.92it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
